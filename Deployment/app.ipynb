{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"app.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOh8ZmzHYXDD8J6nekRV0/w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"diwxnbfJ31gw","executionInfo":{"status":"ok","timestamp":1645779331216,"user_tz":-330,"elapsed":1182,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}}},"outputs":[],"source":["\n","from flask import Flask, jsonify, request, render_template\n","import numpy as np\n","import pandas as pd\n","import sklearn.externals as joblib\n","import pickle\n","from sklearn import preprocessing\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import kurtosis,skew\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","import sklearn.metrics as metrics \n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["import flask\n","app=Flask(__name__)"],"metadata":{"id":"O-Au6tJo4OBt","executionInfo":{"status":"ok","timestamp":1645779337250,"user_tz":-330,"elapsed":171,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["allowedFileExts= {\"csv\"}\n","\n","def checkFileExt(file):\n","    return '.' in file and file.rsplit('.', 1)[1].lower() in allowedFileExts\n","\n","''' Task: Data pre-processing'''\n","\n","def preProcessData(eegdata, dgdata):\n","    print(\"Started - preprocessing\")\n","    eegdata.SubjectID=eegdata.SubjectID.astype(int)\n","    eegdata.VideoID=eegdata.VideoID.astype(int)\n","    eegdata.predefinedlabel=eegdata.predefinedlabel.astype(int)\n","    eegdata['user-definedlabeln']=eegdata['user-definedlabeln'].astype(int)\n","\n","    eegdata.rename(columns = {'predefinedlabel':'TgtLabel', 'user-definedlabeln':'UsrTgtLabel',\n","                          'SubjectID':'SubjectId', 'VideoID':'VideoId'}, inplace = True)\n","\n","    eegdata['SubVdId']=eegdata['SubjectId'].map(str)+'-'+eegdata['VideoId'].map(str)\n","    eegdata['TimeSecs']=eegdata.groupby(['SubjectId','VideoId']).cumcount()+1\n","    videoLength=eegdata[['SubjectId', 'VideoId']].value_counts().to_list()\n","    eegdata=eegdata[eegdata.TimeSecs<=112]\n","    print(\"Number of rows in eegdata: \", len(eegdata))\n","\n","    \n","    demodict={'age': 'Age', 'ethnicity_Bengali' : 'EthnicityBengali',\n","       'ethnicity_English' : 'EthnicityEnglish', 'ethnicity_Han Chinese' : 'EthnicityHanChinese', \n","       'gender_F' : 'Female', 'gender_M' : 'Male', 'subject ID':'SubjectId'}\n","    dgdata.rename(columns=demodict, inplace=True)\n","    dgdata=pd.get_dummies(dgdata)\n","    print(\"Number of rows in dgdata: \", len(dgdata))\n","\n","    return eegdata, dgdata, videoLength\n","\n","\n","'''Task - Create datasets for multiple event epochs - 4,5,6,7,8,9,10,12,15, for any secs segements.\n","Note - Ensure to pass the appropriate event segment paramater value - epochSize'''\n","\n","def fftFeatures(signal, topValues):\n","    fft=np.fft.fft(signal) #Computes the FFT\n","    magSpect=np.round_(np.abs(fft),2) # Extracts the absolute part from the complex numbers\n","    \n","    sortMag=magSpect[np.argsort(magSpect)] #Sorts the magnitude\n","    uniMag=np.unique(sortMag)[-topValues:] #Extract top unique values \n","    \n","    inter, indMag, indUni=np.intersect1d(magSpect,uniMag, return_indices=True) #Gets the timestep index at which these top values occured\n","    #eventInd=np.flip(indMag) #np.sort(indMag) #old logic\n","    eventInd=list(range(len(indMag)))\n","\n","    for n in range(len(indMag)):\n","        num=indMag[n]\n","        if num==0:\n","            eventInd[n]=0\n","        else:\n","            eventInd[n]=np.round(float(1/num),2)\n","    \n","    eventInd=np.flip(eventInd)\n","\n","    return uniMag, eventInd #Returnd the unique top Magnitudes and the respective timestep at which this event magnitude occured\n","\n","\n","def genStatFFTFeatures(dataSub, id, epochSize=10):\n","    #Initialize variables and data structures\n","    st=0\n","    end=len(dataSub)\n","\n","    dat=[]\n","    lbl=[]\n","    #Process from the beginning to the end of the trial\n","    for e in [x for x in range(end) if x%epochSize==0]:\n","    \n","        '''Generate statistical features with the time segment attached as part of the new column generated \n","        after every epochSize per Subject'''\n","        dataStat=dataSub[['SubVdId', 'Delta','Theta','Alpha1','Alpha2','Beta1','Beta2','Gamma1','Gamma2']][e:e+epochSize]\n","        dataStat=dataStat.groupby(['SubVdId']).agg(['mean','std','var','median','min','max', 'skew'])\n","        dataStat.columns = [''.join(str(i) for i in col) for col in dataStat.columns]\n","        nameIndex=e+10\n","        dataStat.columns=[col+'_'+str(nameIndex) for col in dataStat.columns]\n","        lbl.append(dataStat.columns)\n","        dat.append(dataStat.values)\n","\n","    #Create a dataframe by combining the generated column names and statistical features\n","    result=pd.DataFrame(data=np.concatenate(dat).ravel(), columns=['val'])\n","    result['rowIndex']=[item for elem in lbl for item in elem]\n","\n","    magnitude, magnitudeInd=fftFeatures(dataSub['Raw'], topValues=50)\n","    mag=[]\n","    magInd=[]\n","\n","    for m in range(0,len(magnitude)):\n","        colMag='FFTMag_'+str(m)\n","        mag.append(colMag)\n","\n","    for i in range(0,len(magnitudeInd)):\n","        colMagInd='EventMag_'+str(i)\n","        magInd.append(colMagInd)\n","    \n","    dictKey=[*magnitude, *magnitudeInd]\n","    dictVal=[*mag, *magInd]\n","    magDict={'val':dictKey, 'rowIndex':dictVal} #magDict={'val':magnitude, 'colnm':mag}\n","    fftDf=pd.DataFrame(magDict)\n","    result=result.append(fftDf)\n","      \n","    result=pd.pivot_table(result, columns='rowIndex', values='val')\n","    return result\n","\n","\n","\n","#Input data preparation\n","def genFeatures(inpdata):\n","    eegFeatureSet=pd.DataFrame()\n","    svId=inpdata['SubVdId'].unique()\n","    magDict={}\n","\n","    '''Loop through to generate features for all the Subjects.\n","    Remember to pass the appropriate epochSize here in the function call'''\n","    for s in svId:\n","        svDf=inpdata[inpdata['SubVdId']==s]\n","        eegFeatureSet=eegFeatureSet.append(genStatFFTFeatures(dataSub=svDf, id=s, epochSize=10))\n","\n","    '''Create row index for easier identification of the subject combinations.\n","    The videos presented to subjects are of varying length. \n","    Hence for certain shorter video id combinations like 120secs certain features at 140 secs cannot be generated.\n","    Substitute that with median of the respective feature (not 0) else compute the statistical features till 140+secs'''\n","    eegFeatureSet.index=inpdata['SubVdId'].unique()\n","\n","\n","    for n in eegFeatureSet.columns[eegFeatureSet.isnull().any(axis=0)]:\n","        eegFeatureSet[n].fillna(eegFeatureSet[n].median(),inplace=True)\n","    \n","    #eegFeatureSet=eegFeatureSet.replace(np.nan,0)\n","\n","    #eegFeatureSet=np.log(eegFeatureSet)\n","    return eegFeatureSet\n","\n","def addFeatures(inpdata1, inpdata2, inpdata3):\n","    inpdata1['SubjectId']=(inpdata1.index.str.slice(0,1)).astype(int)\n","    inpdata1 = inpdata1.merge(inpdata2, on='SubjectId', how=\"inner\").set_axis(inpdata1.index)\n","    inpdata1['VideoLen']=inpdata3\n","    return inpdata1\n","\n","def dataScaling(inpdata1, inpdata2):\n","    cols=inpdata1.columns\n","\n","    scaler = preprocessing.StandardScaler() #scaler=MinMaxScaler()\n","    output=pd.DataFrame(scaler.fit_transform(inpdata1))\n","    #scaler=scaler.fit(inpdata1)\n","    #output=pd.DataFrame(scaler.transform(inpdata1))\n","    output.columns=cols\n","\n","    y=inpdata2[[\"SubVdId\", \"UsrTgtLabel\"]].groupby(\"SubVdId\").first()\n","    output[\"TgtLabel\"]=y.UsrTgtLabel.to_list()\n","    output.index=inpdata1.index.to_list()\n","\n","    return output\n","\n","\n","def plotConfusionMatrix(predicted, actual):\n","    print(metrics.classification_report(actual, predicted))\n","    cm= plt.subplot()\n","    sns.heatmap(confusion_matrix(predicted,actual), annot=True,  ax=cm, cmap='PiYG')  \n","\n","    # Set the Title, Axis Labels and Class Labels\n","    cm.set_title('Confusion Matrix for Confusion Prediction')\n","    cm.set_xlabel('True Labels');cm.set_ylabel('Predicted Labels') \n","    cm.xaxis.set_ticklabels(['Not Confused', 'Confused']) \n","    cm.yaxis.set_ticklabels(['Not Confused', 'Confused'])"],"metadata":{"id":"QPwqu-gHFzxj","executionInfo":{"status":"ok","timestamp":1645779340365,"user_tz":-330,"elapsed":1004,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["@app.route('/')\n","def welcomePage():\n","    return \"Hello.. you are visiting Declutter-The Clutter page!\""],"metadata":{"id":"o8I_kcFK4amc","executionInfo":{"status":"ok","timestamp":1645779355583,"user_tz":-330,"elapsed":155,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["@app.route('/index')\n","def index():\n","    return flask.render_template('index.html')"],"metadata":{"id":"VcWYz6l842Ua","executionInfo":{"status":"ok","timestamp":1645779357399,"user_tz":-330,"elapsed":151,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["@app.route('/predict', methods=['POST'])\n","def predict():\n","    error=None #Set a default\n","    message=None\n","    if request.method=='POST':\n","        if 'eegfile' not in request.files or 'dgfile' not in request.files:\n","            error='Files are not yet uploaded!'\n","            return render_template('index1.html', error=error) \t\n","\t  \n","\n","\n","        eegfile=request.files['eegfile']\n","        eegfile_path=\"./images/\" + eegfile.filename\n","\n","        dgfile=request.files['dgfile']\n","        dgfile_path=\"./images/\" + dgfile.filename\n","\n","        if eegfile.filename=='' or dgfile.filename=='':\n","            error=\"Choose the files before clicking - Upload\"\n","            return render_template('index1.html', error=error)\n","\n","        if checkFileExt(eegfile.filename)==False or checkFileExt(dgfile.filename)==False:\n","            error=\"Incorrect file type uploaded. Please upload the files with a .csv extension\"\n","            return render_template('index1.html', error=error)\n","\n","        eegfile.save(eegfile_path)\n","        dgfile.save(dgfile_path)\n","        #message=\"EEG and Demographics files verified successfully!\"\n","        #return render_template('message.html', message=message)\n","\n","\n","    \n","\n","        modelFile=pickle.load(open('./model.pkl', 'rb'))\n","\n","        file1=pd.read_csv('./images/eegfile.csv')\n","        file2=pd.read_csv('./images/dgfile.csv')\n","\n","        eegColumns=['SubjectID', 'VideoID', 'Attention', 'Mediation', 'Raw', 'Delta', 'Theta', 'Alpha1', 'Alpha2',\n","                    'Beta1', 'Beta2', 'Gamma1', 'Gamma2', 'predefinedlabel', 'user-definedlabeln']\n","\n","        dgColumns=['subject ID', 'age', 'ethnicity', 'gender']\n","\n","        #Remove the leading/trialing spaces in column names\n","        file1=file1.rename(columns=lambda r: r.strip())\n","        file2=file2.rename(columns=lambda r: r.strip())\n","        file1Columns=file1.columns.to_list()\n","        file2Columns=file2.columns.to_list()\n","\n","        '''Assign the file based on the files content. \n","        Handles if files are not uploaded in an order'''\n","        eegData=dgInfo=pd.DataFrame()\n","        if (file1.columns.to_list()==eegColumns):\n","            eegData=file1\n","        elif (file1.columns.to_list()==dgColumns):\n","            dgInfo=file1\n","        elif (file2.columns.to_list()==eegColumns):\n","            eegData=file2\n","        elif (file2.columns.to_list()==dgColumns):\n","            dgInfo=file2\n","\n","        #Basic checks on files uploaded before the data is processed\n","        if ((len(eegData)==0) or (len(dgInfo)==0)):\n","            error=\"The EEG file has no data to process.\"\n","        elif (eegData.equals(dgInfo)):\n","            error=\"Cannot process EEG data as duplicate csv files have been uploaded.\"\n","        elif (len(eegData)<75): #At over all EEG file level\n","            error=\"Cannot process EEG data as a minimum of 75 timesteps is required.\"\n","        elif ((eegData.isnull().values.any()==True) or (eegData.isnull().sum().sum()!=0) or (np.isinf(df).values.sum()!=0)):\n","            error=\"Cannot process EEG data as NULLs or NAs are present\"\n","\n","        '''Ensures that a minimum of 75 timesteps are present for each Subject-VideoId\n","        combination. Only those Subject-VideoId combinations are processed that meet \n","        this criteria. For combinations that donot meet are not processed and a message\n","        summary is provided at the end of the processing'''\n","        eegCounts=pd.DataFrame(eegData[['SubjectID', 'VideoID']].value_counts()>=75)\n","        if (len(eegCounts)==0):\n","            error=\"Cannot process the EEG data as the Subject-VideoId combinations have timesteps<75\"\n","        else:\n","            eegData.merge(eegCounts[eegCounts[0]==True], on=['SubjectID', 'VideoID'], how='inner')\n","            notProcessed=eegCounts[eegCounts[0]==False].index.to_frame(index=False)\n","\n","\n","\n","        eegData, dgInfo, videoLength = preProcessData(eegData, dgInfo)\n","\n","        #eegData['SubVdId'].value_counts().loc[lambda x : x>=75]\n","\n","        eegFeatureSet=genFeatures(eegData)\n","        eegFeatureSet=addFeatures(eegFeatureSet, dgInfo, videoLength)\n","        eegScaled=dataScaling(eegFeatureSet, eegData) \n","    \n","    \n","        model=modelFile[3]\n","        features=modelFile[2].to_list()\n","        Xtest=eegScaled[features]\n","        ytest=eegScaled.TgtLabel.to_list()\n","\n","        yhat=model.predict(Xtest)\n","        yhat_probabilities=model.predict_proba(Xtest)\n","        '''print('Prediction:', yhat)\n","        if yhat:\n","            prediction=\"Confused\"\n","        else:\n","            prediction=\"Not Confused!\"\n","\n","        #prediction=plotConfusionMatrix(yhat, ytest)'''\n","        prediction=['Confused' if result==1 else 'Not Confused' for result in yhat]\n","    \n","        results=[]\n","        for i in len(predictions):\n","            results[i]=\"The Student-VideoId combination is \"+prediction[i]+\" with a probability of -\"+yhat_probabilities[i]\n","\n","        if(len(unProcessed)!=0):\n","            combinations=list(notProcessed['SubjectID'].map(str)+'-'+notProcessed['VideoID'].map(str))      \n","\n","    return flask.render_template(\"message.html\", results=results, combinations=combinations)\n","    #return jsonify({'The EEG signals, reveal that the student is: ', results})\n","    #notProcessed['SubjectID'].map(str)+'-'+notProcessed['VideoID'].map(str)\n","\n","\n","if __name__=='__main__':\n","    #app.run(host='0.0.0.0', port=8080)\n","    app.run(port=3000, debug=True)"],"metadata":{"id":"2wUuBvwT5Lj7","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"error","timestamp":1645779361995,"user_tz":-330,"elapsed":1322,"user":{"displayName":"Shantala P","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10419282569157795862"}},"outputId":"585f510c-b2d8-4ef0-cdb2-1dbd622271ea"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":[" * Running on http://127.0.0.1:3000/ (Press CTRL+C to quit)\n"," * Restarting with stat\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]},{"cell_type":"code","source":["if __name__=='__main__':\n","    app.run(host='0.0.0.0', port=8080)"],"metadata":{"id":"Nn4Saya2_vY1"},"execution_count":null,"outputs":[]}]}